<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Facial emotion recognition with machine learning | OpenSourceBox</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="Facial Emotion Recognition with Machine Learning
Facial emotion recognition is the capability of identifying and understanding human emotion by analyzing facial expressions. It is a powerful tool used in various industries, including healthcare, marketing, and entertainment. It involves detecting facial features and mapping them to a particular emotion using machine learning algorithms.
In this blog post, we will explore the basics of facial emotion recognition, and how machine learning plays a crucial role in its development.">
    <meta name="generator" content="Hugo 0.111.3">
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    
    
    
      

    

    
    
    <meta property="og:title" content="Facial emotion recognition with machine learning" />
<meta property="og:description" content="Facial Emotion Recognition with Machine Learning
Facial emotion recognition is the capability of identifying and understanding human emotion by analyzing facial expressions. It is a powerful tool used in various industries, including healthcare, marketing, and entertainment. It involves detecting facial features and mapping them to a particular emotion using machine learning algorithms.
In this blog post, we will explore the basics of facial emotion recognition, and how machine learning plays a crucial role in its development." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://opensourcebox.com/posts/facial-emotion-recognition-with-machine-learning/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-09-20T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-09-20T00:00:00+00:00" />
<meta itemprop="name" content="Facial emotion recognition with machine learning">
<meta itemprop="description" content="Facial Emotion Recognition with Machine Learning
Facial emotion recognition is the capability of identifying and understanding human emotion by analyzing facial expressions. It is a powerful tool used in various industries, including healthcare, marketing, and entertainment. It involves detecting facial features and mapping them to a particular emotion using machine learning algorithms.
In this blog post, we will explore the basics of facial emotion recognition, and how machine learning plays a crucial role in its development."><meta itemprop="datePublished" content="2022-09-20T00:00:00+00:00" />
<meta itemprop="dateModified" content="2022-09-20T00:00:00+00:00" />
<meta itemprop="wordCount" content="734">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Facial emotion recognition with machine learning"/>
<meta name="twitter:description" content="Facial Emotion Recognition with Machine Learning
Facial emotion recognition is the capability of identifying and understanding human emotion by analyzing facial expressions. It is a powerful tool used in various industries, including healthcare, marketing, and entertainment. It involves detecting facial features and mapping them to a particular emotion using machine learning algorithms.
In this blog post, we will explore the basics of facial emotion recognition, and how machine learning plays a crucial role in its development."/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        OpenSourceBox
      
    </a>
    <div class="flex-l items-center">
      

      
      
<div class="ananke-socials">
  
</div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        POSTS
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
  </div>


      <h1 class="f1 athelas mt3 mb1">Facial emotion recognition with machine learning</h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2022-09-20T00:00:00Z">September 20, 2022</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p>Facial Emotion Recognition with Machine Learning</p>
<p>Facial emotion recognition is the capability of identifying and understanding human emotion by analyzing facial expressions. It is a powerful tool used in various industries, including healthcare, marketing, and entertainment. It involves detecting facial features and mapping them to a particular emotion using machine learning algorithms.</p>
<p>In this blog post, we will explore the basics of facial emotion recognition, and how machine learning plays a crucial role in its development.</p>
<p>Introduction to Facial Emotion Recognition</p>
<p>Facial emotion recognition has been a topic of interest for many years in psychology and neuroscience. However, with the advent of machine learning techniques, it has become possible to automate and enhance the accuracy of facial emotion recognition systems. The overall process of facial emotion recognition involves the following steps:</p>
<ul>
<li>
<p>Face Detection: The first step is to detect the face in an image or video stream. It involves locating the face using techniques such as Haar Cascade classifiers or deep learning models.</p>
</li>
<li>
<p>Feature Extraction: The next step involves extracting key features of the face, such as eye brows, eyes, nose or mouth, and mapping them to particular emotions. Feature extraction techniques include Local Binary Patterns, Histogram of Oriented Gradients, and Convolutional Neural Networks.</p>
</li>
<li>
<p>Emotion Detection: The final step is to classify the detected facial features into an emotion, such as happy, sad, angry, or surprised. Machine learning algorithms such as Support Vector Machines, Decision Trees, Random Forests, and Deep Neural Networks are used for emotion classification.</p>
</li>
</ul>
<p>Facial emotion recognition systems can be trained using large datasets that contain annotated images or videos of people displaying different emotions. These datasets enable a machine to learn to recognize and classify emotions from facial expressions with high accuracy.</p>
<p>Implementing Facial Emotion Recognition with Machine Learning</p>
<p>To implement a facial emotion recognition system with machine learning, we can follow the following steps:</p>
<ul>
<li>
<p>Collect Datasets: The first step involves gathering datasets of facial expressions. These datasets can be collected from various online resources such as FER-2013, CK+, AffectNet, and EmoReact.</p>
</li>
<li>
<p>Preprocessing of Images: The next step is to preprocess the images in the dataset. This can include applying filters to reduce noise or distortions, resizing the images to a standard size, and cropping the images to focus only on the face.</p>
</li>
<li>
<p>Feature Extraction: The third step involves extracting key features from the images using various techniques such as Local Binary Patterns, Histogram of Oriented Gradients, or Convolutional Neural Networks.</p>
</li>
<li>
<p>Model Selection: The fourth step is to select a machine learning algorithm that is suitable for classifying emotions based on the extracted features. This can include Support Vector Machines, Decision Trees, Random Forests, and Deep Neural Networks.</p>
</li>
<li>
<p>Model Training: The fifth step involves training the selected machine learning algorithm using the collected datasets.</p>
</li>
<li>
<p>Model Evaluation: The final step involves evaluating the trained model&rsquo;s performance using test datasets. Evaluation metrics such as accuracy, precision, recall, and F1 score can be calculated to assess the model&rsquo;s performance.</p>
</li>
</ul>
<p>A sample implementation of facial emotion recognition in Python using the Keras library and the FER-2013 dataset is shown below:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> keras
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras.models <span style="color:#f92672">import</span> Sequential
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras.layers <span style="color:#f92672">import</span> Dense, Conv2D, MaxPooling2D, Dropout, Flatten
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras.preprocessing.image <span style="color:#f92672">import</span> ImageDataGenerator
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load the FER-2013 dataset</span>
</span></span><span style="display:flex;"><span>train_data <span style="color:#f92672">=</span> ImageDataGenerator(rescale<span style="color:#f92672">=</span><span style="color:#ae81ff">1.</span><span style="color:#f92672">/</span><span style="color:#ae81ff">255</span>)
</span></span><span style="display:flex;"><span>train_generator <span style="color:#f92672">=</span> train_data<span style="color:#f92672">.</span>flow_from_directory(
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;fer2013/train&#39;</span>,
</span></span><span style="display:flex;"><span>        target_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">48</span>, <span style="color:#ae81ff">48</span>),
</span></span><span style="display:flex;"><span>        color_mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;grayscale&#39;</span>,
</span></span><span style="display:flex;"><span>        class_mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;categorical&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define the model</span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> Sequential()
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Conv2D(<span style="color:#ae81ff">32</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>, input_shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">48</span>,<span style="color:#ae81ff">48</span>,<span style="color:#ae81ff">1</span>)))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Conv2D(<span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(MaxPooling2D(pool_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>)))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Dropout(<span style="color:#ae81ff">0.25</span>))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Conv2D(<span style="color:#ae81ff">128</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(MaxPooling2D(pool_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>)))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Conv2D(<span style="color:#ae81ff">128</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(MaxPooling2D(pool_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>)))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Dropout(<span style="color:#ae81ff">0.25</span>))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Flatten())
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">1024</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Dropout(<span style="color:#ae81ff">0.5</span>))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">7</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;softmax&#39;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Compile the model</span>
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>compile(loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;categorical_crossentropy&#39;</span>, optimizer<span style="color:#f92672">=</span>keras<span style="color:#f92672">.</span>optimizers<span style="color:#f92672">.</span>Adam(lr<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0001</span>, decay<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-6</span>), metrics<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;accuracy&#39;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Train the model</span>
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>fit_generator(
</span></span><span style="display:flex;"><span>        train_generator,
</span></span><span style="display:flex;"><span>        steps_per_epoch<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>,
</span></span><span style="display:flex;"><span>        epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">15</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Evaluate the model</span>
</span></span><span style="display:flex;"><span>test_data <span style="color:#f92672">=</span> ImageDataGenerator(rescale<span style="color:#f92672">=</span><span style="color:#ae81ff">1.</span><span style="color:#f92672">/</span><span style="color:#ae81ff">255</span>)
</span></span><span style="display:flex;"><span>test_generator <span style="color:#f92672">=</span> test_data<span style="color:#f92672">.</span>flow_from_directory(
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;fer2013/test&#39;</span>,
</span></span><span style="display:flex;"><span>        target_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">48</span>, <span style="color:#ae81ff">48</span>),
</span></span><span style="display:flex;"><span>        color_mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;grayscale&#39;</span>,
</span></span><span style="display:flex;"><span>        class_mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;categorical&#39;</span>)
</span></span><span style="display:flex;"><span>score <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>evaluate_generator(test_generator)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;Test loss:&#39;</span>, score[<span style="color:#ae81ff">0</span>])
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;Test accuracy:&#39;</span>, score[<span style="color:#ae81ff">1</span>])
</span></span></code></pre></div><p>Summary</p>
<p>Facial emotion recognition is a powerful tool that has gained interest in various industries. Machine learning techniques have played a crucial role in automating and enhancing the accuracy of facial emotion recognition systems. The process involves facial detection, feature extraction, and emotion detection. Machine learning algorithms such as Support Vector Machines, Decision Trees, Random Forests, and Deep Neural Networks are used for emotion classification. Implementing a facial emotion recognition system involves collecting datasets, preprocessing images, feature extraction, model selection, model training, and model evaluation.</p>
<p>Additional Resources:</p>
<ol>
<li>Facial Expression Recognition using Deep Learning: A Comprehensive Review: <a href="https://www.sciencedirect.com/science/article/pii/S2090447919302864">https://www.sciencedirect.com/science/article/pii/S2090447919302864</a></li>
<li>Emotion Recognition Using Facial Landmarks, Python, DLib and OpenCV: <a href="https://towardsdatascience.com/emotion-recognition-using-facial-landmarks-python-dlib-and-opencv-2d37315b0055">https://towardsdatascience.com/emotion-recognition-using-facial-landmarks-python-dlib-and-opencv-2d37315b0055</a></li>
<li>FER-2013: Facial Expression Recognition Dataset:https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data</li>
</ol>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://opensourcebox.com/" >
    &copy;  OpenSourceBox 2023 
  </a>
    <div>
<div class="ananke-socials">
  
</div>
</div>
  </div>
</footer>

  </body>
</html>
