<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>GAN(Artificial Intelligence) in action with OpenCV | OpenSourceBox</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="In recent years, Generative Adversarial Networks (GANs) have become incredibly popular in the field of Artificial Intelligence (AI) due to their ability to create new data that is similar to the training data. This has many applications, such as image generation or video synthesis, where GANs can generate new images, videos or even entire scenes on their own. One of the powerful tools used to work with GANs is OpenCV, a powerful open-source computer vision library.">
    <meta name="generator" content="Hugo 0.111.3">
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    
    
    
      

    

    
    
    <meta property="og:title" content="GAN(Artificial Intelligence) in action with OpenCV" />
<meta property="og:description" content="In recent years, Generative Adversarial Networks (GANs) have become incredibly popular in the field of Artificial Intelligence (AI) due to their ability to create new data that is similar to the training data. This has many applications, such as image generation or video synthesis, where GANs can generate new images, videos or even entire scenes on their own. One of the powerful tools used to work with GANs is OpenCV, a powerful open-source computer vision library." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://opensourcebox.com/posts/ganartificial-intelligence-in-action-with-opencv/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-09-20T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-09-20T00:00:00+00:00" />
<meta itemprop="name" content="GAN(Artificial Intelligence) in action with OpenCV">
<meta itemprop="description" content="In recent years, Generative Adversarial Networks (GANs) have become incredibly popular in the field of Artificial Intelligence (AI) due to their ability to create new data that is similar to the training data. This has many applications, such as image generation or video synthesis, where GANs can generate new images, videos or even entire scenes on their own. One of the powerful tools used to work with GANs is OpenCV, a powerful open-source computer vision library."><meta itemprop="datePublished" content="2022-09-20T00:00:00+00:00" />
<meta itemprop="dateModified" content="2022-09-20T00:00:00+00:00" />
<meta itemprop="wordCount" content="851">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="GAN(Artificial Intelligence) in action with OpenCV"/>
<meta name="twitter:description" content="In recent years, Generative Adversarial Networks (GANs) have become incredibly popular in the field of Artificial Intelligence (AI) due to their ability to create new data that is similar to the training data. This has many applications, such as image generation or video synthesis, where GANs can generate new images, videos or even entire scenes on their own. One of the powerful tools used to work with GANs is OpenCV, a powerful open-source computer vision library."/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        OpenSourceBox
      
    </a>
    <div class="flex-l items-center">
      

      
      
<div class="ananke-socials">
  
</div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        POSTS
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
  </div>


      <h1 class="f1 athelas mt3 mb1">GAN(Artificial Intelligence) in action with OpenCV</h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2022-09-20T00:00:00Z">September 20, 2022</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p>In recent years, Generative Adversarial Networks (GANs) have become incredibly popular in the field of Artificial Intelligence (AI) due to their ability to create new data that is similar to the training data. This has many applications, such as image generation or video synthesis, where GANs can generate new images, videos or even entire scenes on their own. One of the powerful tools used to work with GANs is OpenCV, a powerful open-source computer vision library.</p>
<p>In this blog post, we will explore how GANs can be used in practice with OpenCV. We will start by providing a brief overview of GANs, then dive into how to implement them with Python and OpenCV.</p>
<h3 id="what-are-gans">What are GANs?</h3>
<p>Generative Adversarial Networks (GANs) are a type of neural network that consists of two parts: a generator and a discriminator. The generator takes a random noise vector as input and generates a sample similar to the training data. The discriminator, on the other hand, takes in the generated sample and attempts to distinguish it from the real data. During the training, the generator learns to generate samples that are indistinguishable from the real data, while the discriminator learns to distinguish the real data from the generated samples.</p>
<h3 id="gans-in-action">GANs in Action</h3>
<p>There are several ways to use GANs in practice, but one of the most widely used applications is image generation. In this section, we will explore an example of how to use GANs with OpenCV for generating new images.</p>
<p>First, we need to install the necessary libraries. In addition to OpenCV, we will also use the TensorFlow and Keras libraries for our GAN implementation.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>pip install opencv<span style="color:#f92672">-</span>python
</span></span><span style="display:flex;"><span>pip install tensorflow
</span></span><span style="display:flex;"><span>pip install keras
</span></span></code></pre></div><p>Next, we can start by defining our generator and discriminator models. For this example, we will use a simple architecture with a dense layer followed by a reshape layer for the generator and two convolutional layers followed by two dense layers for the discriminator.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> keras <span style="color:#f92672">import</span> Sequential
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras.layers <span style="color:#f92672">import</span> Dense, Reshape, Flatten, Conv2D, Conv2DTranspose
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras.optimizers <span style="color:#f92672">import</span> Adam
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_generator</span>(latent_dim):
</span></span><span style="display:flex;"><span>    generator <span style="color:#f92672">=</span> Sequential()
</span></span><span style="display:flex;"><span>    generator<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">128</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">7</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">7</span>, input_dim<span style="color:#f92672">=</span>latent_dim, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>))
</span></span><span style="display:flex;"><span>    generator<span style="color:#f92672">.</span>add(Reshape((<span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">128</span>)))
</span></span><span style="display:flex;"><span>    generator<span style="color:#f92672">.</span>add(Conv2DTranspose(<span style="color:#ae81ff">128</span>, (<span style="color:#ae81ff">4</span>,<span style="color:#ae81ff">4</span>), strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">2</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;same&#39;</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>))
</span></span><span style="display:flex;"><span>    generator<span style="color:#f92672">.</span>add(Conv2DTranspose(<span style="color:#ae81ff">128</span>, (<span style="color:#ae81ff">4</span>,<span style="color:#ae81ff">4</span>), strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">2</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;same&#39;</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>))
</span></span><span style="display:flex;"><span>    generator<span style="color:#f92672">.</span>add(Conv2D(<span style="color:#ae81ff">1</span>, (<span style="color:#ae81ff">7</span>,<span style="color:#ae81ff">7</span>), activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;sigmoid&#39;</span>, padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;same&#39;</span>))
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> generator
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_discriminator</span>(img_shape):
</span></span><span style="display:flex;"><span>    discriminator <span style="color:#f92672">=</span> Sequential()
</span></span><span style="display:flex;"><span>    discriminator<span style="color:#f92672">.</span>add(Conv2D(<span style="color:#ae81ff">64</span>, (<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>), strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">2</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;same&#39;</span>, input_shape<span style="color:#f92672">=</span>img_shape, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>))
</span></span><span style="display:flex;"><span>    discriminator<span style="color:#f92672">.</span>add(Conv2D(<span style="color:#ae81ff">128</span>, (<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>), strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">2</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;same&#39;</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>))
</span></span><span style="display:flex;"><span>    discriminator<span style="color:#f92672">.</span>add(Flatten())
</span></span><span style="display:flex;"><span>    discriminator<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">128</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>))
</span></span><span style="display:flex;"><span>    discriminator<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">1</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;sigmoid&#39;</span>))
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> discriminator
</span></span></code></pre></div><p>After defining the models, we can initialize and compile them with the following code.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>img_shape <span style="color:#f92672">=</span> (<span style="color:#ae81ff">28</span>,<span style="color:#ae81ff">28</span>,<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>latent_dim <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Build the discriminator</span>
</span></span><span style="display:flex;"><span>discriminator <span style="color:#f92672">=</span> build_discriminator(img_shape)
</span></span><span style="display:flex;"><span>discriminator<span style="color:#f92672">.</span>compile(loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;binary_crossentropy&#39;</span>, optimizer<span style="color:#f92672">=</span>Adam(), metrics<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;accuracy&#39;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Build the generator</span>
</span></span><span style="display:flex;"><span>generator <span style="color:#f92672">=</span> build_generator(latent_dim)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># The generator takes noise as input and generates imgs</span>
</span></span><span style="display:flex;"><span>z <span style="color:#f92672">=</span> Input(shape<span style="color:#f92672">=</span>(latent_dim,))
</span></span><span style="display:flex;"><span>img <span style="color:#f92672">=</span> generator(z)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># For the combined model we will only train the generator</span>
</span></span><span style="display:flex;"><span>discriminator<span style="color:#f92672">.</span>trainable <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># The discriminator takes generated images as input and determines validity</span>
</span></span><span style="display:flex;"><span>valid <span style="color:#f92672">=</span> discriminator(img)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># The combined model links the generator and discriminator</span>
</span></span><span style="display:flex;"><span>combined <span style="color:#f92672">=</span> Model(z, valid)
</span></span><span style="display:flex;"><span>combined<span style="color:#f92672">.</span>compile(loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;binary_crossentropy&#39;</span>, optimizer<span style="color:#f92672">=</span>Adam())
</span></span></code></pre></div><p>Now, we can train the GAN with real images taken from the MNIST dataset.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> keras.datasets <span style="color:#f92672">import</span> mnist
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load the dataset</span>
</span></span><span style="display:flex;"><span>(X_train, _), (_, _) <span style="color:#f92672">=</span> mnist<span style="color:#f92672">.</span>load_data()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Rescale -1 to 1</span>
</span></span><span style="display:flex;"><span>X_train <span style="color:#f92672">=</span> X_train <span style="color:#f92672">/</span> <span style="color:#ae81ff">127.5</span> <span style="color:#f92672">-</span> <span style="color:#ae81ff">1.</span>
</span></span><span style="display:flex;"><span>X_train <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>expand_dims(X_train, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Train the discriminator</span>
</span></span><span style="display:flex;"><span>valid <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>ones((batch_size, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>fake <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros((batch_size, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(epochs):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Select a random batch of images</span>
</span></span><span style="display:flex;"><span>    idx <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>randint(<span style="color:#ae81ff">0</span>, X_train<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>], batch_size)
</span></span><span style="display:flex;"><span>    imgs <span style="color:#f92672">=</span> X_train[idx]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Generate a batch of new images</span>
</span></span><span style="display:flex;"><span>    noise <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, (batch_size, latent_dim))
</span></span><span style="display:flex;"><span>    gen_imgs <span style="color:#f92672">=</span> generator<span style="color:#f92672">.</span>predict(noise)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Train the discriminator</span>
</span></span><span style="display:flex;"><span>    d_loss_real <span style="color:#f92672">=</span> discriminator<span style="color:#f92672">.</span>train_on_batch(imgs, valid)
</span></span><span style="display:flex;"><span>    d_loss_fake <span style="color:#f92672">=</span> discriminator<span style="color:#f92672">.</span>train_on_batch(gen_imgs, fake)
</span></span><span style="display:flex;"><span>    d_loss <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.5</span> <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>add(d_loss_real, d_loss_fake)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Train the generator</span>
</span></span><span style="display:flex;"><span>    noise <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, (batch_size, latent_dim))
</span></span><span style="display:flex;"><span>    g_loss <span style="color:#f92672">=</span> combined<span style="color:#f92672">.</span>train_on_batch(noise, valid)
</span></span></code></pre></div><p>After training the GAN, we can sample from the generator to generate new images.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Generate a random noise vector</span>
</span></span><span style="display:flex;"><span>noise <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, (<span style="color:#ae81ff">1</span>, latent_dim))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Generate a new image</span>
</span></span><span style="display:flex;"><span>gen_img <span style="color:#f92672">=</span> generator<span style="color:#f92672">.</span>predict(noise)[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Rescale the image from [-1,1] to [0,1]</span>
</span></span><span style="display:flex;"><span>gen_img <span style="color:#f92672">=</span> (<span style="color:#ae81ff">0.5</span> <span style="color:#f92672">*</span> gen_img <span style="color:#f92672">+</span> <span style="color:#ae81ff">0.5</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Display the image</span>
</span></span><span style="display:flex;"><span>cv2<span style="color:#f92672">.</span>imshow(<span style="color:#e6db74">&#39;Generated Image&#39;</span>, gen_img)
</span></span><span style="display:flex;"><span>cv2<span style="color:#f92672">.</span>waitKey(<span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>cv2<span style="color:#f92672">.</span>destroyAllWindows()
</span></span></code></pre></div><h3 id="conclusion">Conclusion</h3>
<p>In this blog post, we explored how to use GANs with OpenCV for image generation. We started by providing an overview of GANs and then dove into the implementation details using Python and OpenCV. We explored how to define the generator and discriminator models, how to initialize and compile them, and how to train the GAN. Finally, we generated new images using the trained GAN.</p>
<p>This is just one example of GANs in action with OpenCV. GANs have many applications, such as video synthesis, and can be used to generate data for a wide range of purposes. If you want to learn more about GANs, you can check out the following resources:</p>
<ul>
<li><a href="https://github.com/hindupuravinash/the-gan-zoo">The GAN Zoo</a>: A collection of GAN implementations in TensorFlow.</li>
<li><a href="https://www.oreilly.com/library/view/generative-deep-learning/9781492041931/">Generative Deep Learning</a>: A book on generative modeling with deep learning.</li>
<li><a href="https://github.com/PauliSairanen/python-ai-opencv-gan">GitHub repository for this project</a>: The source code for this project.</li>
</ul>
<p>We hope this blog post has given you a better understanding of how GANs can be used with OpenCV for image generation. If you have any questions or comments, please feel free to leave them below!</p>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://opensourcebox.com/" >
    &copy;  OpenSourceBox 2023 
  </a>
    <div>
<div class="ananke-socials">
  
</div>
</div>
  </div>
</footer>

  </body>
</html>
