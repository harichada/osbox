<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Generative Models In Action | OpenSourceBox</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="Generative models are machine learning algorithms that can learn from observed data points to produce new data points that possess similar characteristics to the original dataset. These models generate new data by modeling the distribution of the original dataset, allowing them to create samples that are statistically similar to the original data.
One of the most popular generative models is the Generative Adversarial Networks (GANs). Generative Adversarial Networks (GAN), introduced in 2014 by Ian Goodfellow, is a fascinating concept.">
    <meta name="generator" content="Hugo 0.111.3">
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    
    
    
      

    

    
    
    <meta property="og:title" content="Generative Models In Action" />
<meta property="og:description" content="Generative models are machine learning algorithms that can learn from observed data points to produce new data points that possess similar characteristics to the original dataset. These models generate new data by modeling the distribution of the original dataset, allowing them to create samples that are statistically similar to the original data.
One of the most popular generative models is the Generative Adversarial Networks (GANs). Generative Adversarial Networks (GAN), introduced in 2014 by Ian Goodfellow, is a fascinating concept." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://opensourcebox.com/posts/generative-models-in-action/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-09-20T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-09-20T00:00:00+00:00" />
<meta itemprop="name" content="Generative Models In Action">
<meta itemprop="description" content="Generative models are machine learning algorithms that can learn from observed data points to produce new data points that possess similar characteristics to the original dataset. These models generate new data by modeling the distribution of the original dataset, allowing them to create samples that are statistically similar to the original data.
One of the most popular generative models is the Generative Adversarial Networks (GANs). Generative Adversarial Networks (GAN), introduced in 2014 by Ian Goodfellow, is a fascinating concept."><meta itemprop="datePublished" content="2022-09-20T00:00:00+00:00" />
<meta itemprop="dateModified" content="2022-09-20T00:00:00+00:00" />
<meta itemprop="wordCount" content="1029">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Generative Models In Action"/>
<meta name="twitter:description" content="Generative models are machine learning algorithms that can learn from observed data points to produce new data points that possess similar characteristics to the original dataset. These models generate new data by modeling the distribution of the original dataset, allowing them to create samples that are statistically similar to the original data.
One of the most popular generative models is the Generative Adversarial Networks (GANs). Generative Adversarial Networks (GAN), introduced in 2014 by Ian Goodfellow, is a fascinating concept."/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        OpenSourceBox
      
    </a>
    <div class="flex-l items-center">
      

      
      
<div class="ananke-socials">
  
</div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        POSTS
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
  </div>


      <h1 class="f1 athelas mt3 mb1">Generative Models In Action</h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2022-09-20T00:00:00Z">September 20, 2022</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p>Generative models are machine learning algorithms that can learn from observed data points to produce new data points that possess similar characteristics to the original dataset. These models generate new data by modeling the distribution of the original dataset, allowing them to create samples that are statistically similar to the original data.</p>
<p>One of the most popular generative models is the Generative Adversarial Networks (GANs). Generative Adversarial Networks (GAN), introduced in 2014 by Ian Goodfellow, is a fascinating concept. GANs have two primary components, the generator network and discriminator network. The generator network takes random noise input and generates synthetic data, while the discriminator network attempts to differentiate between the synthetic data and real data.</p>
<p>GANs improved over previous generative techniques by relying on the idea of game theory to train two neural networks simultaneously, with a generator creating fake samples while a discriminator tries to identify whether each sample is real or fake. The two networks learn from each other until training stops.</p>
<p>Generative models come in handy when dealing with tasks such as data imputation, anomaly detection, captioning, and image synthesis. In this blog post, we will explore two applications of Generative Models, namely:</p>
<ol>
<li>
<p>Image Generation</p>
</li>
<li>
<p>Language Generation</p>
</li>
</ol>
<h3 id="image-generation">Image Generation</h3>
<p>Generative Models can come up with a new image based on input noise in high-dimensional space. Convolutional Neural Networks (CNNs) have been incredibly successful in image classification, with state-of-the-art architectures such as ResNet and DenseNet.</p>
<p>However, one of the biggest problems of generative models is that it is difficult to evaluate their performance. If we assume that we generate a new image from the learned distribution, there is no easy way to verify if the generated image is sensible to a human observer.</p>
<p>We can use <a href="https://github.com/soumik12345/DCGAN_Keras">Deep Convolutional Generative Adversarial Networks (DCGAN)</a> to generate new images from input noise. Let&rsquo;s create a generator and a discriminator network:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras.layers <span style="color:#f92672">import</span> Input
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras.layers <span style="color:#f92672">import</span> Dense, Dropout, Flatten, Conv2D, Conv2DTranspose, Reshape, LeakyReLU, Activation
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras <span style="color:#f92672">import</span> layers
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras <span style="color:#f92672">import</span> models
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras.optimizers <span style="color:#f92672">import</span> Adam
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">discriminator</span>():
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    input_layer <span style="color:#f92672">=</span> Input(shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">28</span>, <span style="color:#ae81ff">28</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Conv2D(<span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;same&#34;</span>)(input_layer)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> LeakyReLU(alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Dropout(<span style="color:#ae81ff">0.25</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Conv2D(<span style="color:#ae81ff">128</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>), strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">2</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;same&#34;</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> LeakyReLU(alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Dropout(<span style="color:#ae81ff">0.25</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Conv2D(<span style="color:#ae81ff">256</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>), strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">2</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;same&#34;</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> LeakyReLU(alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Dropout(<span style="color:#ae81ff">0.25</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Conv2D(<span style="color:#ae81ff">512</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>), strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">2</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;same&#34;</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> LeakyReLU(alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Dropout(<span style="color:#ae81ff">0.25</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Flatten()(x)
</span></span><span style="display:flex;"><span>    output_layer <span style="color:#f92672">=</span> Dense(<span style="color:#ae81ff">1</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;sigmoid&#39;</span>)(x)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    model <span style="color:#f92672">=</span> models<span style="color:#f92672">.</span>Model(inputs<span style="color:#f92672">=</span>[input_layer], outputs<span style="color:#f92672">=</span>[output_layer])
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> model
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">generator</span>():
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    input_layer <span style="color:#f92672">=</span> Input(shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">100</span>,))
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Dense(<span style="color:#ae81ff">7</span><span style="color:#f92672">*</span><span style="color:#ae81ff">7</span><span style="color:#f92672">*</span><span style="color:#ae81ff">256</span>)(input_layer)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Activation(<span style="color:#e6db74">&#39;relu&#39;</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Reshape((<span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">256</span>))(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Conv2DTranspose(<span style="color:#ae81ff">128</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>), strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">2</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;same&#34;</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Activation(<span style="color:#e6db74">&#39;relu&#39;</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Conv2DTranspose(<span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>), strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">2</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;same&#34;</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Activation(<span style="color:#e6db74">&#39;relu&#39;</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Conv2DTranspose(<span style="color:#ae81ff">1</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;same&#34;</span>)(x)
</span></span><span style="display:flex;"><span>    output_layer <span style="color:#f92672">=</span> Activation(<span style="color:#e6db74">&#39;tanh&#39;</span>)(x)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    model <span style="color:#f92672">=</span> models<span style="color:#f92672">.</span>Model(inputs<span style="color:#f92672">=</span>[input_layer], outputs<span style="color:#f92672">=</span>[output_layer])
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> model
</span></span></code></pre></div><p>Here, we created our discriminator and generator network. We will now combine the two and train them using the MNIST dataset.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> tqdm <span style="color:#f92672">import</span> tqdm
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># load mnist dataset</span>
</span></span><span style="display:flex;"><span>(X_train, y_train), (_, _) <span style="color:#f92672">=</span> keras<span style="color:#f92672">.</span>datasets<span style="color:#f92672">.</span>mnist<span style="color:#f92672">.</span>load_data()
</span></span><span style="display:flex;"><span>X_train <span style="color:#f92672">=</span> X_train<span style="color:#f92672">.</span>reshape(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">28</span>, <span style="color:#ae81ff">28</span>, <span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>astype(<span style="color:#e6db74">&#34;float32&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># normalize pixel values</span>
</span></span><span style="display:flex;"><span>X_train <span style="color:#f92672">=</span> X_train <span style="color:#f92672">/</span> <span style="color:#ae81ff">127.5</span> <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Batch and shuffle data</span>
</span></span><span style="display:flex;"><span>dataset <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>Dataset<span style="color:#f92672">.</span>from_tensor_slices(X_train)<span style="color:#f92672">.</span>shuffle(<span style="color:#ae81ff">10000</span>)<span style="color:#f92672">.</span>batch(<span style="color:#ae81ff">256</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>d_optimizer <span style="color:#f92672">=</span> Adam(learning_rate<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0002</span>, beta_1<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>)
</span></span><span style="display:flex;"><span>g_optimizer <span style="color:#f92672">=</span> Adam(learning_rate<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0002</span>, beta_1<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># training function</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">@tf.function</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">train_step</span>(images):
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    noise <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal([<span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">100</span>])
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>GradientTape() <span style="color:#66d9ef">as</span> gen_tape, tf<span style="color:#f92672">.</span>GradientTape() <span style="color:#66d9ef">as</span> disc_tape:
</span></span><span style="display:flex;"><span>        generated_images <span style="color:#f92672">=</span> generator(noise, training<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        real_output <span style="color:#f92672">=</span> discriminator(images, training<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        fake_output <span style="color:#f92672">=</span> discriminator(generated_images, training<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        gen_loss <span style="color:#f92672">=</span> generator_loss(fake_output)
</span></span><span style="display:flex;"><span>        disc_loss <span style="color:#f92672">=</span> discriminator_loss(real_output, fake_output)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    gradients_of_generator <span style="color:#f92672">=</span> gen_tape<span style="color:#f92672">.</span>gradient(gen_loss, generator<span style="color:#f92672">.</span>trainable_variables)
</span></span><span style="display:flex;"><span>    gradients_of_discriminator <span style="color:#f92672">=</span> disc_tape<span style="color:#f92672">.</span>gradient(disc_loss, discriminator<span style="color:#f92672">.</span>trainable_variables)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    g_optimizer<span style="color:#f92672">.</span>apply_gradients(zip(gradients_of_generator, generator<span style="color:#f92672">.</span>trainable_variables))
</span></span><span style="display:flex;"><span>    d_optimizer<span style="color:#f92672">.</span>apply_gradients(zip(gradients_of_discriminator, discriminator<span style="color:#f92672">.</span>trainable_variables))
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> gen_loss, disc_loss
</span></span></code></pre></div><pre tabindex="0"><code>def generator_loss(fake_output):
    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)
    return cross_entropy(tf.ones_like(fake_output), fake_output)

def discriminator_loss(real_output, fake_output):
    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss
</code></pre><p>Finally, we can train our GAN model using 50 epochs:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>num_epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">50</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(num_epochs):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> image_batch <span style="color:#f92672">in</span> tqdm(dataset):
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        gen_loss, disc_loss <span style="color:#f92672">=</span> train_step(image_batch)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> epoch <span style="color:#f92672">%</span> <span style="color:#ae81ff">5</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>        plt<span style="color:#f92672">.</span>imshow(generated_images<span style="color:#f92672">.</span>numpy()[<span style="color:#ae81ff">0</span>, :, :, <span style="color:#ae81ff">0</span>], cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;gray&#39;</span>)
</span></span><span style="display:flex;"><span>        plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;Epoch: &#34;</span> <span style="color:#f92672">+</span> str(epoch))
</span></span><span style="display:flex;"><span>        plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p><img src="https://user-images.githubusercontent.com/30522566/138008358-ab2bc0bd-b7aa-41c1-9f82-c81cc152b0f0.png" alt="image"></p>
<h3 id="language-generation">Language Generation</h3>
<p>In this section, we will explore how we can generate textual data using LSTM networks. LSTM networks are widely used in natural language processing (NLP) as they are great at capturing long-term dependencies among words.</p>
<p>To generate text using LSTM, we must create a language model. A language model can predict the probability distribution of a given sequence of words. It can predict the probability of the next word given the previous words in the sequence.</p>
<p>Let&rsquo;s build an LSTM model that generates new text based on the input text.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> keras.layers <span style="color:#f92672">import</span> Embedding, LSTM, Dense
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras.models <span style="color:#f92672">import</span> Sequential
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras.utils <span style="color:#f92672">import</span> to_categorical
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras.preprocessing.sequence <span style="color:#f92672">import</span> pad_sequences
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras.preprocessing.text <span style="color:#f92672">import</span> Tokenizer
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> open(<span style="color:#e6db74">&#34;frankenstein.txt&#34;</span>)<span style="color:#f92672">.</span>read()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokenizer <span style="color:#f92672">=</span> Tokenizer(char_level<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>tokenizer<span style="color:#f92672">.</span>fit_on_texts(text)
</span></span><span style="display:flex;"><span>num_chars <span style="color:#f92672">=</span> len(tokenizer<span style="color:#f92672">.</span>word_index)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sequences <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1</span>, len(text)):
</span></span><span style="display:flex;"><span>    seq <span style="color:#f92672">=</span> text[i<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>:i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>    sequences<span style="color:#f92672">.</span>append(seq)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sequences <span style="color:#f92672">=</span> tokenizer<span style="color:#f92672">.</span>texts_to_sequences(sequences)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X, y <span style="color:#f92672">=</span> [], []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> sequences:
</span></span><span style="display:flex;"><span>    X<span style="color:#f92672">.</span>append(i[<span style="color:#ae81ff">0</span>])
</span></span><span style="display:flex;"><span>    y<span style="color:#f92672">.</span>append(i[<span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(X)
</span></span><span style="display:flex;"><span>y <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_train <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>reshape(X, (X<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>], <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>y_train <span style="color:#f92672">=</span> to_categorical(y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> Sequential()
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Embedding(num_chars<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">32</span>, input_length<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(LSTM(<span style="color:#ae81ff">32</span>))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Dense(num_chars<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;softmax&#39;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>compile(loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;categorical_crossentropy&#39;</span>, optimizer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;adam&#39;</span>, metrics<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;accuracy&#39;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>fit(X_train, y_train, batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">128</span>, epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>)
</span></span></code></pre></div><p>With this code, we trained the model for 100 epochs. We can now generate new text using the model.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># generate sequence of characters</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">generate_seq</span>(seed_text, n_chars):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(n_chars):
</span></span><span style="display:flex;"><span>        seq <span style="color:#f92672">=</span> tokenizer<span style="color:#f92672">.</span>texts_to_sequences([seed_text])[<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>        seq <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>reshape(seq, (<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        result <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>predict_classes(seq, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>        out_char <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> char, index <span style="color:#f92672">in</span> tokenizer<span style="color:#f92672">.</span>word_index<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> index <span style="color:#f92672">==</span> result:
</span></span><span style="display:flex;"><span>                out_char <span style="color:#f92672">=</span> char
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>        seed_text <span style="color:#f92672">+=</span> out_char
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> seed_text
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># generate 100 new characters</span>
</span></span><span style="display:flex;"><span>generated_text <span style="color:#f92672">=</span> generate_seq(<span style="color:#e6db74">&#39;Melting, and presently I&#39;</span>, <span style="color:#ae81ff">100</span>)
</span></span><span style="display:flex;"><span>print(generated_text)
</span></span></code></pre></div><pre tabindex="0"><code>Melting, and presently I left them in frank and with his change in at him.  These if there was so heartless
and a particular excitement, these soothing of the men Weth a little would haviors in as
</code></pre><p>In conclusion, Generative Models are a great success in the Machine Learning world. The two main fields of applications for Generative Models in action are Image generation and Language generation. In this blog post, we developed two Generative Models to generate images and text, respectively. Finally, we can generate an image using a GAN, and we can generate the text with an LSTM network.</p>
<h2 id="additional-links">Additional Links</h2>
<ul>
<li><a href="https://blog.floydhub.com/gans-story-so-far/">Generative Models for Image Generation</a></li>
<li><a href="https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/">Generative Models with Keras</a></li>
<li><a href="https://towardsdatascience.com/how-to-build-a-simple-lstm-letter-generator-rnn-82e8e1019a00">Generative Models for Language Generation</a></li>
<li><a href="https://towardsdatascience.com/reproducible-research-in-python-5-ways-to-improve-your-workflow-8e5b6f823d6a">Reproducible Research in Python</a></li>
</ul>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://opensourcebox.com/" >
    &copy;  OpenSourceBox 2023 
  </a>
    <div>
<div class="ananke-socials">
  
</div>
</div>
  </div>
</footer>

  </body>
</html>
