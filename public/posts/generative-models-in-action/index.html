<!DOCTYPE html>

<html lang="en-us">
<head>

<title>OpenSourceBox | Generative Models In Action</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
    <link rel="apple-touch-icon" sizes="180x180" href='/favicon/apple-touch-icon.png'>
    <link rel="icon" type="image/png" sizes="32x32" href='/favicon/favicon-32x32.png'>
    <link rel="icon" type="image/png" sizes="16x16" href='/favicon/favicon-16x16.png'>
    <link rel="manifest" href='/favicon/site.webmanifest' />
    <link rel="mask-icon" href=' /favicon/safari-pinned-tab.svg' color="#5bbad5" />
    <link rel="shortcut icon" href='/favicon/favicon.ico' />
    <meta name="theme-color" content="#ffffff">
    <meta property="og:title" content="OpenSourceBox | Generative Models In Action" />
    
    
    
    <link rel="stylesheet" href="/css/style.min.ef88d3b5be8646161728d2c8b8a5e9edfda1e59b414b00c424a9936397884558.css" />
    
    <link href=' /css/blonde.min.css' rel="stylesheet" type="text/css" media="print"
        onload="this.media=' all'">
    



<meta name="description" content="Generative models are machine learning algorithms that can learn from observed data points to produce new data points that possess similar characteristics to the original dataset. These models generate new data by modeling the distribution of the original dataset, allowing them to create samples that are statistically similar to the original data.
One of the most popular generative models is the Generative Adversarial Networks (GANs). Generative Adversarial Networks (GAN), introduced in 2014 by Ian Goodfellow, is a fascinating concept.">
<meta property="og:site_name" content="OpenSourceBox">
<meta property="og:description" content="Generative models are machine learning algorithms that can learn from observed data points to produce new data points that possess similar characteristics to the original dataset. These models generate new data by modeling the distribution of the original dataset, allowing them to create samples that are statistically similar to the original data.
One of the most popular generative models is the Generative Adversarial Networks (GANs). Generative Adversarial Networks (GAN), introduced in 2014 by Ian Goodfellow, is a fascinating concept.">
<meta property="og:url" content="http://opensourcebox.com/posts/generative-models-in-action/">
<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="">

<link rel="canonical" href="http://opensourcebox.com/posts/generative-models-in-action/">

<meta name="twitter:description" content="Generative models are machine learning algorithms that can learn from observed data points to produce new data points that possess similar characteristics to the original dataset. These models generate new data by modeling the distribution of the original dataset, allowing them to create samples that are statistically similar to the original data.
One of the most popular generative models is the Generative Adversarial Networks (GANs). Generative Adversarial Networks (GAN), introduced in 2014 by Ian Goodfellow, is a fascinating concept.">
<meta property="article:published_time" content="2022-09-20T00:00:00&#43;00:00">
<meta property="article:updated_time" content="2022-09-20T00:00:00&#43;00:00">





<meta property="og:image" content="http://opensourcebox.com/">
<meta property="og:image:url" content="http://opensourcebox.com/">

    
    <link rel="stylesheet" href='/css/custom.css'>
    <i class="dark hidden"></i>
</head>
<body class="font-sans">
    <div class="min-h-screen flex flex-col bg-gray-100 dark:bg-warmgray-800"><div class="">
    <div class="container max-w-screen-xl mr-auto ml-auto">
        <nav class="flex items-center justify-between flex-wrap  p-6">
            <div class="flex items-center flex-no-shrink  text-white mr-6">
                <a href="http://opensourcebox.com/"><span class="font-semibold text-2xl tracking-tight">OpenSourceBox</span></a>
            </div>
            <div class="flex md:hidden">
                <div class="py-2">
                    <button onclick="toggleDarkMode()" class="focus:outline-none mr-1" aria-label="Darkmode Toggle Button"><i id="icon"
                            class="icon-moon inline-flex align-middle leading-normal text-lg text-white"></i></button>
                    <span class="text-white">|</span>
                </div>
                <button id="hamburgerbtn" class="flex items-center px-3 py-1 text-white hover:opacity-50" aria-label="Hamburger Button">
                    <span class="icon-menu text-2xl"></span>
                </button>
            </div>
            <div class="hidden w-full md:flex md:flex-row sm:items-center md:w-auto" id="mobileMenu">
                <div class="text-sm lg:flex-grow">
                </div>
                <div class="navmenu">
                    
                </div>
                <div class="text-white invisible md:visible">
                    <span>|</span>
                    <button onclick="toggleDarkMode()" class="focus-visible:outline-none" aria-label="Darkmode Toggle Button"><i id="icon2"
                            class="icon-moon hover:opacity-50 duration-200 inline-flex align-middle leading-normal text-lg ml-2"></i></button>
                </div>
            </div>
        </nav>
    </div>
</div>
<style>
    .active {
        display: block;
    }
</style>

<script>
    let hamburger = document.getElementById('hamburgerbtn');

    let mobileMenu = document.getElementById('mobileMenu');

    hamburger.addEventListener('click', function () {
        mobileMenu.classList.toggle('active');
    });
</script>
<div class="container max-w-screen-xl mx-auto mt-4 flex-grow px-5 lg:px-0" id="content">
            <div class="lg:mx-5">
<div class="grid grid-cols-3 gap-4">
    
        <div class="bg-white col-span-3 p-5 dark:bg-warmgray-900 dark:text-white">
            
            <h1 class="title text-4xl font-bold mb-2">Generative Models In Action</h1>
            <div class="content prose md:prose-lg lg:prose-xl max-w-none dark:prose-invert py-1"><p>Generative models are machine learning algorithms that can learn from observed data points to produce new data points that possess similar characteristics to the original dataset. These models generate new data by modeling the distribution of the original dataset, allowing them to create samples that are statistically similar to the original data.</p>
<p>One of the most popular generative models is the Generative Adversarial Networks (GANs). Generative Adversarial Networks (GAN), introduced in 2014 by Ian Goodfellow, is a fascinating concept. GANs have two primary components, the generator network and discriminator network. The generator network takes random noise input and generates synthetic data, while the discriminator network attempts to differentiate between the synthetic data and real data.</p>
<p>GANs improved over previous generative techniques by relying on the idea of game theory to train two neural networks simultaneously, with a generator creating fake samples while a discriminator tries to identify whether each sample is real or fake. The two networks learn from each other until training stops.</p>
<p>Generative models come in handy when dealing with tasks such as data imputation, anomaly detection, captioning, and image synthesis. In this blog post, we will explore two applications of Generative Models, namely:</p>
<ol>
<li>
<p>Image Generation</p>
</li>
<li>
<p>Language Generation</p>
</li>
</ol>
<h3 id="image-generation">Image Generation</h3>
<p>Generative Models can come up with a new image based on input noise in high-dimensional space. Convolutional Neural Networks (CNNs) have been incredibly successful in image classification, with state-of-the-art architectures such as ResNet and DenseNet.</p>
<p>However, one of the biggest problems of generative models is that it is difficult to evaluate their performance. If we assume that we generate a new image from the learned distribution, there is no easy way to verify if the generated image is sensible to a human observer.</p>
<p>We can use <a href="https://github.com/soumik12345/DCGAN_Keras">Deep Convolutional Generative Adversarial Networks (DCGAN)</a> to generate new images from input noise. Let&rsquo;s create a generator and a discriminator network:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras.layers <span style="color:#f92672">import</span> Input
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras.layers <span style="color:#f92672">import</span> Dense, Dropout, Flatten, Conv2D, Conv2DTranspose, Reshape, LeakyReLU, Activation
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras <span style="color:#f92672">import</span> layers
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras <span style="color:#f92672">import</span> models
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras.optimizers <span style="color:#f92672">import</span> Adam
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">discriminator</span>():
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    input_layer <span style="color:#f92672">=</span> Input(shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">28</span>, <span style="color:#ae81ff">28</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Conv2D(<span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;same&#34;</span>)(input_layer)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> LeakyReLU(alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Dropout(<span style="color:#ae81ff">0.25</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Conv2D(<span style="color:#ae81ff">128</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>), strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">2</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;same&#34;</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> LeakyReLU(alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Dropout(<span style="color:#ae81ff">0.25</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Conv2D(<span style="color:#ae81ff">256</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>), strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">2</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;same&#34;</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> LeakyReLU(alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Dropout(<span style="color:#ae81ff">0.25</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Conv2D(<span style="color:#ae81ff">512</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>), strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">2</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;same&#34;</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> LeakyReLU(alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Dropout(<span style="color:#ae81ff">0.25</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Flatten()(x)
</span></span><span style="display:flex;"><span>    output_layer <span style="color:#f92672">=</span> Dense(<span style="color:#ae81ff">1</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;sigmoid&#39;</span>)(x)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    model <span style="color:#f92672">=</span> models<span style="color:#f92672">.</span>Model(inputs<span style="color:#f92672">=</span>[input_layer], outputs<span style="color:#f92672">=</span>[output_layer])
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> model
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">generator</span>():
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    input_layer <span style="color:#f92672">=</span> Input(shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">100</span>,))
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Dense(<span style="color:#ae81ff">7</span><span style="color:#f92672">*</span><span style="color:#ae81ff">7</span><span style="color:#f92672">*</span><span style="color:#ae81ff">256</span>)(input_layer)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Activation(<span style="color:#e6db74">&#39;relu&#39;</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Reshape((<span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">256</span>))(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Conv2DTranspose(<span style="color:#ae81ff">128</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>), strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">2</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;same&#34;</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Activation(<span style="color:#e6db74">&#39;relu&#39;</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Conv2DTranspose(<span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>), strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">2</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;same&#34;</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Activation(<span style="color:#e6db74">&#39;relu&#39;</span>)(x)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> Conv2DTranspose(<span style="color:#ae81ff">1</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;same&#34;</span>)(x)
</span></span><span style="display:flex;"><span>    output_layer <span style="color:#f92672">=</span> Activation(<span style="color:#e6db74">&#39;tanh&#39;</span>)(x)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    model <span style="color:#f92672">=</span> models<span style="color:#f92672">.</span>Model(inputs<span style="color:#f92672">=</span>[input_layer], outputs<span style="color:#f92672">=</span>[output_layer])
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> model
</span></span></code></pre></div><p>Here, we created our discriminator and generator network. We will now combine the two and train them using the MNIST dataset.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> tqdm <span style="color:#f92672">import</span> tqdm
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># load mnist dataset</span>
</span></span><span style="display:flex;"><span>(X_train, y_train), (_, _) <span style="color:#f92672">=</span> keras<span style="color:#f92672">.</span>datasets<span style="color:#f92672">.</span>mnist<span style="color:#f92672">.</span>load_data()
</span></span><span style="display:flex;"><span>X_train <span style="color:#f92672">=</span> X_train<span style="color:#f92672">.</span>reshape(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">28</span>, <span style="color:#ae81ff">28</span>, <span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>astype(<span style="color:#e6db74">&#34;float32&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># normalize pixel values</span>
</span></span><span style="display:flex;"><span>X_train <span style="color:#f92672">=</span> X_train <span style="color:#f92672">/</span> <span style="color:#ae81ff">127.5</span> <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Batch and shuffle data</span>
</span></span><span style="display:flex;"><span>dataset <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>Dataset<span style="color:#f92672">.</span>from_tensor_slices(X_train)<span style="color:#f92672">.</span>shuffle(<span style="color:#ae81ff">10000</span>)<span style="color:#f92672">.</span>batch(<span style="color:#ae81ff">256</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>d_optimizer <span style="color:#f92672">=</span> Adam(learning_rate<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0002</span>, beta_1<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>)
</span></span><span style="display:flex;"><span>g_optimizer <span style="color:#f92672">=</span> Adam(learning_rate<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0002</span>, beta_1<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># training function</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">@tf.function</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">train_step</span>(images):
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    noise <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal([<span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">100</span>])
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>GradientTape() <span style="color:#66d9ef">as</span> gen_tape, tf<span style="color:#f92672">.</span>GradientTape() <span style="color:#66d9ef">as</span> disc_tape:
</span></span><span style="display:flex;"><span>        generated_images <span style="color:#f92672">=</span> generator(noise, training<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        real_output <span style="color:#f92672">=</span> discriminator(images, training<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        fake_output <span style="color:#f92672">=</span> discriminator(generated_images, training<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        gen_loss <span style="color:#f92672">=</span> generator_loss(fake_output)
</span></span><span style="display:flex;"><span>        disc_loss <span style="color:#f92672">=</span> discriminator_loss(real_output, fake_output)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    gradients_of_generator <span style="color:#f92672">=</span> gen_tape<span style="color:#f92672">.</span>gradient(gen_loss, generator<span style="color:#f92672">.</span>trainable_variables)
</span></span><span style="display:flex;"><span>    gradients_of_discriminator <span style="color:#f92672">=</span> disc_tape<span style="color:#f92672">.</span>gradient(disc_loss, discriminator<span style="color:#f92672">.</span>trainable_variables)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    g_optimizer<span style="color:#f92672">.</span>apply_gradients(zip(gradients_of_generator, generator<span style="color:#f92672">.</span>trainable_variables))
</span></span><span style="display:flex;"><span>    d_optimizer<span style="color:#f92672">.</span>apply_gradients(zip(gradients_of_discriminator, discriminator<span style="color:#f92672">.</span>trainable_variables))
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> gen_loss, disc_loss
</span></span></code></pre></div><pre tabindex="0"><code>def generator_loss(fake_output):
    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)
    return cross_entropy(tf.ones_like(fake_output), fake_output)

def discriminator_loss(real_output, fake_output):
    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss
</code></pre><p>Finally, we can train our GAN model using 50 epochs:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>num_epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">50</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(num_epochs):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> image_batch <span style="color:#f92672">in</span> tqdm(dataset):
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        gen_loss, disc_loss <span style="color:#f92672">=</span> train_step(image_batch)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> epoch <span style="color:#f92672">%</span> <span style="color:#ae81ff">5</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>        plt<span style="color:#f92672">.</span>imshow(generated_images<span style="color:#f92672">.</span>numpy()[<span style="color:#ae81ff">0</span>, :, :, <span style="color:#ae81ff">0</span>], cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;gray&#39;</span>)
</span></span><span style="display:flex;"><span>        plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;Epoch: &#34;</span> <span style="color:#f92672">+</span> str(epoch))
</span></span><span style="display:flex;"><span>        plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p><img src="https://user-images.githubusercontent.com/30522566/138008358-ab2bc0bd-b7aa-41c1-9f82-c81cc152b0f0.png" alt="image"></p>
<h3 id="language-generation">Language Generation</h3>
<p>In this section, we will explore how we can generate textual data using LSTM networks. LSTM networks are widely used in natural language processing (NLP) as they are great at capturing long-term dependencies among words.</p>
<p>To generate text using LSTM, we must create a language model. A language model can predict the probability distribution of a given sequence of words. It can predict the probability of the next word given the previous words in the sequence.</p>
<p>Let&rsquo;s build an LSTM model that generates new text based on the input text.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> keras.layers <span style="color:#f92672">import</span> Embedding, LSTM, Dense
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras.models <span style="color:#f92672">import</span> Sequential
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras.utils <span style="color:#f92672">import</span> to_categorical
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras.preprocessing.sequence <span style="color:#f92672">import</span> pad_sequences
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras.preprocessing.text <span style="color:#f92672">import</span> Tokenizer
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> open(<span style="color:#e6db74">&#34;frankenstein.txt&#34;</span>)<span style="color:#f92672">.</span>read()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokenizer <span style="color:#f92672">=</span> Tokenizer(char_level<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>tokenizer<span style="color:#f92672">.</span>fit_on_texts(text)
</span></span><span style="display:flex;"><span>num_chars <span style="color:#f92672">=</span> len(tokenizer<span style="color:#f92672">.</span>word_index)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sequences <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1</span>, len(text)):
</span></span><span style="display:flex;"><span>    seq <span style="color:#f92672">=</span> text[i<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>:i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>    sequences<span style="color:#f92672">.</span>append(seq)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sequences <span style="color:#f92672">=</span> tokenizer<span style="color:#f92672">.</span>texts_to_sequences(sequences)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X, y <span style="color:#f92672">=</span> [], []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> sequences:
</span></span><span style="display:flex;"><span>    X<span style="color:#f92672">.</span>append(i[<span style="color:#ae81ff">0</span>])
</span></span><span style="display:flex;"><span>    y<span style="color:#f92672">.</span>append(i[<span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(X)
</span></span><span style="display:flex;"><span>y <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_train <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>reshape(X, (X<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>], <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>y_train <span style="color:#f92672">=</span> to_categorical(y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> Sequential()
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Embedding(num_chars<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">32</span>, input_length<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(LSTM(<span style="color:#ae81ff">32</span>))
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>add(Dense(num_chars<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;softmax&#39;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>compile(loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;categorical_crossentropy&#39;</span>, optimizer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;adam&#39;</span>, metrics<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;accuracy&#39;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>fit(X_train, y_train, batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">128</span>, epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>)
</span></span></code></pre></div><p>With this code, we trained the model for 100 epochs. We can now generate new text using the model.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># generate sequence of characters</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">generate_seq</span>(seed_text, n_chars):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(n_chars):
</span></span><span style="display:flex;"><span>        seq <span style="color:#f92672">=</span> tokenizer<span style="color:#f92672">.</span>texts_to_sequences([seed_text])[<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>        seq <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>reshape(seq, (<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        result <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>predict_classes(seq, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>        out_char <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> char, index <span style="color:#f92672">in</span> tokenizer<span style="color:#f92672">.</span>word_index<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> index <span style="color:#f92672">==</span> result:
</span></span><span style="display:flex;"><span>                out_char <span style="color:#f92672">=</span> char
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>        seed_text <span style="color:#f92672">+=</span> out_char
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> seed_text
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># generate 100 new characters</span>
</span></span><span style="display:flex;"><span>generated_text <span style="color:#f92672">=</span> generate_seq(<span style="color:#e6db74">&#39;Melting, and presently I&#39;</span>, <span style="color:#ae81ff">100</span>)
</span></span><span style="display:flex;"><span>print(generated_text)
</span></span></code></pre></div><pre tabindex="0"><code>Melting, and presently I left them in frank and with his change in at him.  These if there was so heartless
and a particular excitement, these soothing of the men Weth a little would haviors in as
</code></pre><p>In conclusion, Generative Models are a great success in the Machine Learning world. The two main fields of applications for Generative Models in action are Image generation and Language generation. In this blog post, we developed two Generative Models to generate images and text, respectively. Finally, we can generate an image using a GAN, and we can generate the text with an LSTM network.</p>
<h2 id="additional-links">Additional Links</h2>
<ul>
<li><a href="https://blog.floydhub.com/gans-story-so-far/">Generative Models for Image Generation</a></li>
<li><a href="https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/">Generative Models with Keras</a></li>
<li><a href="https://towardsdatascience.com/how-to-build-a-simple-lstm-letter-generator-rnn-82e8e1019a00">Generative Models for Language Generation</a></li>
<li><a href="https://towardsdatascience.com/reproducible-research-in-python-5-ways-to-improve-your-workflow-8e5b6f823d6a">Reproducible Research in Python</a></li>
</ul>
</div>
        </div>
        
    </div>
    
            </div>
        </div><footer class=" text-white p-6">
  
  <div class="container max-w-screen-xl mr-auto ml-auto">
    <p>&copy; 2023 <a href="http://opensourcebox.com/" class="duration-200 hover:opacity-50">OpenSourceBox</a>
    </p>
    <p>Powered by <a href="https://gohugo.io/" class="duration-200 hover:opacity-50">Hugo</a>, Theme <a
        href="https://github.com/opera7133/Blonde" class="duration-200 hover:opacity-50">Blonde</a>.</p>
  </div>
  
  <script>
    var icon = document.getElementById("icon");
    var icon2 = document.getElementById("icon2");
    
    if (document.documentElement.classList.contains("dark") || localStorage.theme === 'dark' || (!('theme' in localStorage) && window.matchMedia('(prefers-color-scheme: dark)').matches)) {
      icon.classList.remove("icon-moon");
      icon.classList.add("icon-sun");
      icon2.classList.remove("icon-moon");
      icon2.classList.add("icon-sun");
      document.documentElement.classList.add('dark')
    } else {
      document.documentElement.classList.remove('dark')
    }
    function toggleDarkMode() {
      if (document.documentElement.classList.contains('dark')) {
        icon.classList.remove("icon-sun");
        icon.classList.add("icon-moon");
        icon2.classList.remove("icon-sun");
        icon2.classList.add("icon-moon");
        document.documentElement.classList.remove('dark')
        localStorage.theme = 'light'
      } else {
        icon.classList.remove("icon-moon");
        icon.classList.add("icon-sun");
        icon2.classList.remove("icon-moon");
        icon2.classList.add("icon-sun");
        document.documentElement.classList.add('dark')
        localStorage.theme = 'dark'
      }
    }
  </script>
</footer></div>
</body>

</html>
